{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb1262-83ea-41cb-8822-32e961f85625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbcls_llm.client import DBCLSLLMClient\n",
    "from dbcls_llm.config import MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13162c-6ae9-478e-a69f-af3e2ab682b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ada4af-e69c-4566-b2c8-2b1ac623ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_client(model):\n",
    "    return DBCLSLLMClient(username=\"*\", password=\"*\", model_info=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249654c-df98-4082-a9f3-94769df96664",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBCLSLLMClient.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6f514-4feb-4087-94bf-08cc5672568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = {}\n",
    "models = list(MODELS.keys())\n",
    "models.remove('gemini')\n",
    "for key in models:\n",
    "    if 'gpt' in key:\n",
    "        clients[key] = make_client(MODELS[key][0])\n",
    "    else:\n",
    "        for model in MODELS[key]:\n",
    "          clients[key+model['model']] = make_client(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c17ea-b8df-44b0-815e-e5325247a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510fd99-4fbf-4ebe-8628-4fea34214173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(client, prompt):\n",
    "    try:\n",
    "        res = client.query(prompt).text\n",
    "    except Exception as e:\n",
    "        res = \"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f029770-2169-4252-b225-a18385b04aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def query_client(cp):\n",
    "    return query(cp[0], cp[1])\n",
    "\n",
    "prompt1 = 'hi'\n",
    "results = []\n",
    "#Using ThreadPoolExecutor to run encoding in parallel\n",
    "#with ThreadPoolExecutor() as executor:\n",
    "#    results = dict(zip(\n",
    "#        clients.keys(), list(executor.map(query_client, zip(clients.values(), [prompt1 for x in range(len(clients))])))))\n",
    "# for client in clients.values():\n",
    "#     results.append(query(client, prompt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf43ab-0960-4916-aae8-8e7ab91ba085",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214aa024-e644-4443-a746-585887f43bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_all(prompt):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = dict(zip(\n",
    "            clients.keys(), list(executor.map(query_client, zip(clients.values(), [prompt for x in range(len(clients))])))))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fde56-074f-414a-b0f2-1f5ac6a0b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_all('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d88622-2bba-4739-9160-c93b3e8d6925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc649045-2b5b-461b-94e3-9de7d7f70653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"allenai/WildChat-1M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022f88a-2c6b-46d4-b2c2-7f7fda907528",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit initial_prompts = [d[0]['content'] for d in ds['train'][:]['conversation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b6004-3d62-40d4-8097-bb25946cd653",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('questions.pkl', 'rb') as f:  # Open file in read-binary mode\n",
    "    questions = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324b37b-514d-4289-bb41-b00a800a0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4524d-0af0-4f0f-b7bc-7439b903b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_MSG_KEYS = [\"bioinformatics\",\"biology\",\"microbiology\",\"notype\",\"genus\",\"phylum\",\"taxonomy\",\"Prokaryote \",\"Bacteria\",\"fungi\",\"fungal\",\"virus\",\"Eukaryote\",\" gene \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8c3f4-d62a-4208-9d5a-ad42605a14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions = []\n",
    "for question in questions:\n",
    "    found = False\n",
    "    for keyword in KEEP_MSG_KEYS:\n",
    "        if keyword in question:\n",
    "            found = True\n",
    "    filtered_questions.append((found, question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bbad2-0fd8-4924-a0c7-a4bb5a5dd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b09df-624b-463a-bc70-e3f7835cd1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_array.pkl', 'rb') as f:  # Open file in read-binary mode\n",
    "    loaded_data = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7be70-6488-4e8d-b25c-099a3e37d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a04dc6-bc63-437d-82f2-422ec517d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = query_all('say hi back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b5e14-0a3e-4893-864a-457708c20114",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1bf5c-0c29-4c8e-825c-164c4ccc938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7b89d-ad95-4197-8cfd-2f9d4d6f05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comparing_output = []\n",
    "i = 1445+18\n",
    "print(len(filtered_questions))\n",
    "for question in filtered_questions[i:]:\n",
    "    res = {}\n",
    "    print(i)\n",
    "    if question[0]:\n",
    "        try:\n",
    "            if question[0]:\n",
    "                res = query_all(question[1])\n",
    "            comparing_output.append((question[0], question[1], res))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with question index {i}: {e}\")\n",
    "            # Optionally, append a default value or None for error cases\n",
    "            comparing_output.append((question[0], question[1], {}))\n",
    "    else:\n",
    "        comparing_output.append((question[0], question[1], res))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba44c3b-4b47-4ad0-be92-9f91f9a6664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comparing_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41c2f3-3e0c-451a-9907-aaeaf040bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('benchmark.pkl', 'wb') as f:  # Open file in write-binary mode\n",
    "    pickle.dump(comparing_output, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3ee3f-c276-41c0-a442-ad470006de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea105c4-42e7-4860-ad4e-48bac627d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comparing_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c584b-be4b-4d7d-9e98-763987d6329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_output = [x for x in comparing_output if x[2] != {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c0a9b-6bf7-4d91-93d1-b347207314ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149376a8-bbe1-4eac-8620-c79561a239d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_output[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863d4ee-520d-425e-9acd-7bb1fdb085fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit allp = [(d[0]['content'], d[1]['content']) for d in ds['train'][:]['conversation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae894c7-0713-479b-b805-b0e99a91f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_conv = []\n",
    "for conv in allp:\n",
    "    found = False\n",
    "    for keyword in KEEP_MSG_KEYS:\n",
    "        if keyword in conv[0]:\n",
    "            found = True\n",
    "    tagged_conv.append((found, conv[0], conv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef01dd-3603-40bc-9fb0-a099d7599147",
   "metadata": {},
   "outputs": [],
   "source": [
    "bds = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d01c69-852a-46aa-ae34-c0c157b8d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 41941\n",
    "print(len(ds['train']))\n",
    "for row in ds['train']:\n",
    "    print(i)\n",
    "    prompt = row['conversation'][0]['content']\n",
    "    res = {}\n",
    "    found = False\n",
    "    for keyword in KEEP_MSG_KEYS:\n",
    "        if keyword in prompt:\n",
    "            found = True\n",
    "    if found:\n",
    "        try:\n",
    "            res = query_all(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with question index {i}: {e}\")\n",
    "    row['compare'] = res\n",
    "    bds.append(row)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82bb453-8403-487e-82c9-e25c1838fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232a541-2f40-43bd-97a7-e44e9b7234e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('benchmark.pkl', 'wb') as f:  # Open file in write-binary mode\n",
    "    pickle.dump(bds, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb71000c-467f-497a-810a-eefe8d4669ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bds[168]['compare']['llamallama2-70b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e58aea-1724-414e-ba12-b115e1d8fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comparisons = bds[168]['compare']\n",
    "just_one_response = bds[168]['compare']['llamallama2-70b']\n",
    "original_prompt = bds[168]['conversation'][0]['content']\n",
    "original_response = bds[168]['conversation'][1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f8ea0-2880-4bea-a6e3-9d567ab5c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e27158-06b2-4ef8-8081-c24751025549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('benchmark_lg.pkl', 'wb') as f:  # Open file in write-binary mode\n",
    "    pickle.dump(bds, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4b6b33-9a3f-4fb1-9fbe-bddefa615c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7bcc41e-72de-441d-917f-c60b76a852c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidcs/git/dbcls_llm/env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "#!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# noinspection PyPackageRequirements\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762b05e-620d-4448-8514-c1b892bf4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 96009\n",
    "for row in bdx[i:]:\n",
    "    print(i)\n",
    "    #row['prompt'] = row['conversation'][0]['content']\n",
    "    row['prompt-embed'] = model.encode(row['conversation'][0]['content'])\n",
    "    #row['response'] = row['conversation'][1]['content']\n",
    "    row['response-embed'] = model.encode(row['conversation'][1]['content'])\n",
    "    # print(row)\n",
    "    row['embeddings'] = {}\n",
    "    i+= 1\n",
    "    if row['compare'] != {}:\n",
    "        for key in row['compare'].keys():\n",
    "            if row['compare'].get(key, None):\n",
    "                row['embeddings'][key] = model.encode(row['compare'][key])\n",
    "        # calculate distance from original response\n",
    "        row['response-ldistances'] = {}\n",
    "        row['response-sdistances'] = {}\n",
    "        row['response-similarity'] = {}\n",
    "        for key in row['embeddings'].keys():\n",
    "            row['response-ldistances'][key] = Levenshtein.distance(row['conversation'][1]['content'], row['compare'][key])\n",
    "            if min(len(row['conversation'][1]['content']), len(row['compare'][key])) > 0:\n",
    "                max_len = max(len(row['conversation'][1]['content']), len(row['compare'][key]))\n",
    "                similarity = 1 - (row['response-ldistances'][key] / max_len)\n",
    "                row['response-similarity'][key] = similarity\n",
    "            else:\n",
    "                row['response-similarity'][key] = 0\n",
    "            # embedded distance\n",
    "            row['response-sdistances'][key] = sum(row['embeddings'][key] - row['response-embed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d3ee9-84e7-438e-b4c9-2cc710e3417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7273178-679f-43d6-b9c6-6a9cc55b849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdx[168]['response-similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e894101-8a13-4a93-8ab4-b26d0b52528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('benchmark_lg.pkl', 'rb') as f:  # Open file in write-binary mode\n",
    "    bdx = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc58c8e-b573-4778-99d9-d96a84ece46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('benchmark_lg_embed-distance-2.pkl', 'wb') as f:  # Open file in write-binary mode\n",
    "    pickle.dump(bdx, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad6bfc-9277-4568-8eba-1129493ba1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('benchmark_lg_embed-distance.pkl', 'rb') as f:  # Open file in write-binary mode\n",
    "    bdv = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6dede2f-033f-44ce-974d-3d74d28ef2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for row in bdx:\n",
    "    if row.get('embeddings', {}) != {}:\n",
    "        i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793f67c-62d4-46f6-950d-e51f1afa5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('benchmark_326800_embed-distance.pkl', 'wb') as f:  # Open file in write-binary mode\n",
    "    pickle.dump(bdx, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92dbf0d-0784-4eda-9a41-9cb5f17ce966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-35-turbo': np.float32(-0.16393547),\n",
       " 'gpt-4o': np.float32(-0.22431158),\n",
       " 'gpt-4': np.float32(-0.084557414),\n",
       " 'claude3opus': np.float32(-0.32143763),\n",
       " 'claude3sonnet5': np.float32(-0.26128024),\n",
       " 'claude3sonnet': np.float32(0.42277068),\n",
       " 'claude3haiku': np.float32(-0.018462598),\n",
       " 'commandrplus': np.float32(-0.054872647),\n",
       " 'commandrbasic': np.float32(-0.13524169),\n",
       " 'llamallama3-70b': np.float32(1.6736692),\n",
       " 'llamallama3-8b': np.float32(-0.12971321),\n",
       " 'llamallama2-70b': np.float32(0.055728346),\n",
       " 'llamallama2-13b': np.float32(0.39503032),\n",
       " 'mistralmistral-7b': np.float32(-0.2246772),\n",
       " 'mistralmixtral-8x7b': np.float32(-0.07445856),\n",
       " 'mistralmistral-large': np.float32(0.14975908)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdx[168]['response-sdistances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b00fc94-9c8a-43a9-a1df-d141ab248eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f7614-48d9-4b8c-8894-90e843114765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last finished amount\n",
    "# 326800"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
